Search.setIndex({"docnames": ["ExampleUsage", "GettingStarted", "api_doc", "index"], "filenames": ["ExampleUsage.rst", "GettingStarted.rst", "api_doc.rst", "index.rst"], "titles": ["Example Usage", "Retrieving the dataset", "FigCapsHF Documentation", "Welcome to the documentation for Figure-Captioning with Human Feedback benchmark dataset!"], "terms": {"requir": 0, "clone": 0, "repositori": 0, "download": [0, 1, 2], "benchmark": [0, 1], "dataset": [0, 2], "pip": 0, "upgrad": 0, "git": 0, "http": [0, 1, 2], "github": [0, 2], "com": [0, 1, 2], "figcapshf": [0, 3], "r": 0, "txt": 0, "wget": [0, 1], "figshar": [0, 1], "ndownload": [0, 1], "file": [0, 1], "41222934": [0, 1], "o": [0, 1], "zip": [0, 1], "unzip": [0, 1], "To": [0, 3], "train": [0, 1, 2], "blip": [0, 2], "model": [0, 2, 3], "while": 0, "choos": [0, 2], "factor": [0, 2], "code": [0, 3], "edit": 0, "implement": 0, "baselin": 0, "ar": [0, 2], "also": [0, 2], "includ": [0, 2], "train_blip": 0, "py": 0, "If": [0, 2], "cpu": 0, "add": 0, "flag": 0, "python": 0, "mixed_precis": 0, "fp16": 0, "hf_score_typ": [0, 2], "help": [0, 2], "benchmark_path": [0, 2], "xx": 0, "our": [0, 3], "can": [0, 1, 2, 3], "here": [0, 1, 3], "2": [0, 2, 3], "5": 0, "gb": [0, 1, 3], "caption": [0, 1, 2], "singl": [0, 1, 2], "imag": [0, 1, 2], "figure_path": 0, "path": [0, 2], "sampl": [0, 2], "png": [0, 2], "model_path": 0, "pth": 0, "evalu": [0, 1, 3], "metric": 0, "test": [0, 1, 2], "test_blip": 0, "from": [0, 1, 2], "import": 0, "data": [0, 2], "get_image_caption_pair": [0, 2], "data_split": [0, 2], "image_nam": [0, 2], "1001": 0, "0025v1": 0, "figure5": 0, "1": [0, 3], "an": [0, 2, 3], "annot": [0, 2], "its": 0, "associ": 0, "get_image_caption_pair_hf": [0, 2], "1907": 0, "11521v1": 0, "figure6": 0, "metadata": [0, 1, 2], "embedding_model": [0, 2], "bert": [0, 2], "scibert": [0, 2], "mcse": [0, 2], "ocr": [0, 2], "takeawai": [0, 2], "inferred_hf_df": [0, 2], "infer_hf_training_set": [0, 2], "max_num_sampl": [0, 2], "100": [0, 1], "quantization_level": [0, 2], "3": 0, "mapped_hf_label": [0, 2], "bad": [0, 2], "neutral": 0, "good": [0, 2], "score": [0, 2], "figur": [0, 1, 2], "pair": [0, 1, 2, 3], "hf_ds_embed": [0, 2], "generate_embeddings_hf_anno": [0, 2], "scoring_model": [0, 2], "train_scoring_model": [0, 2], "image_path": [0, 2], "graph": 0, "indic": 0, "loss": 0, "over": 0, "success": 0, "embed": [0, 2], "generate_embed": [0, 2], "inferred_hf_scor": 0, "predict": [0, 2], "The": [1, 3], "8": [1, 3], "34": [1, 3], "manual": 1, "run": 1, "follow": 1, "command": 1, "directori": 1, "structur": 1, "i": [1, 2], "No": [1, 2], "subfig": [1, 2], "img": [1, 2], "contain": [1, 2], "each": [1, 2], "split": [1, 2], "val": [1, 2], "all": [1, 2], "correspond": [1, 2], "precomput": 1, "infer": [1, 2], "human": [1, 2], "feedback": [1, 2], "csv": 1, "subset": 1, "arxiv": 1, "oai": 1, "snapshot": 1, "json": 1, "paper": 1, "list": [1, 2], "experi": 1, "name": [1, 2], "us": [1, 2], "sentenc": 1, "ye": 1, "first": [1, 2], "same": 1, "more": 1, "than": 1, "token": 1, "class": 2, "main": 2, "captions_list": 2, "mcse_path": 2, "none": 2, "gener": [2, 3], "specifi": 2, "given": 2, "paramet": 2, "string": 2, "select": 2, "suppli": 2, "folder": 2, "weight": 2, "return": 2, "type": 2, "n": 2, "d": 2, "numpi": 2, "arrai": 2, "note": 2, "flickr": 2, "roberta": 2, "base": 2, "robert": 2, "ud": 2, "lsv": 2, "generate_embeddings_ds_split": 2, "split_nam": 2, "larger": 2, "default": 2, "natur": 2, "number": 2, "maximum": 2, "pick": 2, "ds_split_embed": 2, "400": 2, "between": 2, "visual": 2, "empti": 2, "remov": 2, "generate_jsonl": 2, "jsonl": 2, "": 2, "place": 2, "under": 2, "respect": 2, "verifi": 2, "consist": 2, "larg": [2, 3], "where": 2, "locat": 2, "withou": 2, "suffix": 2, "hf": [2, 3], "without": 2, "infer_hf": 2, "unseen": 2, "which": 2, "need": 2, "scikit": 2, "learn": [2, 3], "mlp": 2, "regressor": 2, "ha": 2, "been": 2, "calcul": 2, "differ": 2, "percentil": 2, "quantiz": 2, "level": 2, "bin": 2, "higher": 2, "inferred_scor": 2, "quantized_scor": 2, "label": 2, "row": 2, "file_nam": 2, "text": 2, "inferred_hf": 2, "quantized_hf": 2, "mapped_hf": 2, "map": 2, "panda": 2, "datafram": 2, "hf_embed": 2, "desir": 2, "target": 2, "enabl": 3, "high": 3, "qualiti": 3, "we": 3, "introduc": 3, "figcap": 3, "new": 3, "framework": 3, "incorpor": 3, "domain": 3, "expert": 3, "optim": 3, "reader": 3, "prefer": 3, "compris": 3, "automat": 3, "method": 3, "novel": 3, "reinforc": 3, "rlhf": 3, "releas": 3, "scale": 3, "further": 3, "develop": 3, "techniqu": 3, "thi": 3, "problem": 3, "found": 3, "retriev": 3, "exampl": 3, "usag": 3}, "objects": {"": [[2, 0, 0, "-", "FigCapsHF"]], "FigCapsHF": [[2, 1, 1, "", "FigCapsHF"]], "FigCapsHF.FigCapsHF": [[2, 2, 1, "", "generate_embeddings"], [2, 2, 1, "", "generate_embeddings_ds_split"], [2, 2, 1, "", "generate_embeddings_hf_anno"], [2, 2, 1, "", "generate_jsonl"], [2, 2, 1, "", "get_image_caption_pair"], [2, 2, 1, "", "get_image_caption_pair_hf"], [2, 2, 1, "", "infer_hf"], [2, 2, 1, "", "infer_hf_training_set"], [2, 2, 1, "", "train_scoring_model"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"]}, "titleterms": {"exampl": 0, "usag": 0, "instal": 0, "rlhf": 0, "fine": 0, "tune": 0, "infer": 0, "visual": 0, "human": [0, 3], "feedback": [0, 3], "gener": 0, "retriev": 1, "dataset": [1, 3], "figcapshf": 2, "document": [2, 3], "welcom": 3, "figur": 3, "caption": 3, "benchmark": 3, "content": 3}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"Example Usage": [[0, "example-usage"]], "Installation": [[0, "installation"]], "RLHF Fine-tuning": [[0, "rlhf-fine-tuning"]], "Inference": [[0, "inference"]], "Visualization": [[0, "visualization"]], "Human Feedback Generation": [[0, "human-feedback-generation"]], "Retrieving the dataset": [[1, "retrieving-the-dataset"]], "FigCapsHF Documentation": [[2, "module-FigCapsHF"]], "Welcome to the documentation for Figure-Captioning with Human Feedback benchmark dataset!": [[3, "welcome-to-the-documentation-for-figure-captioning-with-human-feedback-benchmark-dataset"]], "Contents": [[3, "contents"]]}, "indexentries": {"figcapshf": [[2, "module-FigCapsHF"]], "figcapshf (class in figcapshf)": [[2, "FigCapsHF.FigCapsHF"]], "generate_embeddings() (figcapshf.figcapshf method)": [[2, "FigCapsHF.FigCapsHF.generate_embeddings"]], "generate_embeddings_ds_split() (figcapshf.figcapshf method)": [[2, "FigCapsHF.FigCapsHF.generate_embeddings_ds_split"]], "generate_embeddings_hf_anno() (figcapshf.figcapshf method)": [[2, "FigCapsHF.FigCapsHF.generate_embeddings_hf_anno"]], "generate_jsonl() (figcapshf.figcapshf method)": [[2, "FigCapsHF.FigCapsHF.generate_jsonl"]], "get_image_caption_pair() (figcapshf.figcapshf method)": [[2, "FigCapsHF.FigCapsHF.get_image_caption_pair"]], "get_image_caption_pair_hf() (figcapshf.figcapshf method)": [[2, "FigCapsHF.FigCapsHF.get_image_caption_pair_hf"]], "infer_hf() (figcapshf.figcapshf method)": [[2, "FigCapsHF.FigCapsHF.infer_hf"]], "infer_hf_training_set() (figcapshf.figcapshf method)": [[2, "FigCapsHF.FigCapsHF.infer_hf_training_set"]], "module": [[2, "module-FigCapsHF"]], "train_scoring_model() (figcapshf.figcapshf method)": [[2, "FigCapsHF.FigCapsHF.train_scoring_model"]]}})