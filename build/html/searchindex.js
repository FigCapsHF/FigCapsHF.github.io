Search.setIndex({"docnames": ["ExampleUsage", "GettingStarted", "api_doc", "index"], "filenames": ["ExampleUsage.rst", "GettingStarted.rst", "api_doc.rst", "index.rst"], "titles": ["Example Usage", "Retrieving the dataset", "API Documentation", "Welcome to the documentation for Figure-Captioning with Human Feedback benchmark dataset!"], "terms": {"thi": 0, "i": [0, 1, 2], "an": [0, 2], "fine": 0, "tune": 0, "blip": [0, 2], "model": [0, 2], "figur": [0, 2], "caption": [0, 1, 2], "us": [0, 2], "huggingfac": 0, "": [0, 2], "dataset": [0, 2], "class": [0, 2], "our": [0, 3], "rlhf": [0, 3], "first": [0, 1, 2], "we": 0, "download": [0, 1, 2], "depend": 0, "clone": 0, "repo": [0, 3], "helper": 0, "function": 0, "pip": 0, "instal": 0, "upgrad": 0, "git": 0, "http": [0, 1, 2], "github": [0, 2, 3], "com": [0, 1, 2], "figcapshf": [0, 2], "figcap": 0, "cd": 0, "r": 0, "requir": 0, "txt": 0, "wget": [0, 1], "figshar": [0, 1], "ndownload": [0, 1], "file": [0, 1], "40317607": [0, 1], "o": [0, 1], "zip": [0, 1], "unzip": [0, 1], "cp": 0, "sh": 0, "here": [0, 3], "ar": [0, 2], "sampl": [0, 2], "train": [0, 1, 2], "pytorch": 0, "nativ": 0, "dataload": 0, "librari": 0, "combin": 0, "user": 0, "can": [0, 1, 2, 3], "provid": [0, 3], "argument": 0, "desir": [0, 2], "shown": 0, "script": 0, "below": 0, "To": [0, 1], "chang": 0, "number": [0, 2], "epoch": 0, "learn": [0, 2, 3], "rate": 0, "modifi": 0, "config": 0, "variabl": 0, "train_blip": 0, "py": 0, "python": 0, "f16": 0, "output_dir": 0, "output": 0, "after": 0, "set": 0, "up": 0, "predict": [0, 2], "scientif": [0, 3], "from": [0, 2], "imag": [0, 2], "code": 0, "block": 0, "pred": 0, "link": [0, 1], "pre": 0, "place": [0, 2], "under": 0, "directori": [0, 1], "follow": [0, 1], "do": [0, 1], "infer": [0, 2], "png": [0, 2], "you": 1, "either": 1, "manual": 1, "through": 1, "run": 1, "command": 1, "The": [1, 3], "structur": 1, "benchmark": 1, "arxiv": 1, "metadata": [1, 2], "oai": 1, "snapshot": 1, "json": 1, "human": [1, 2], "feedback": [1, 2], "csv": 1, "all": [1, 2], "test": [1, 2], "val": [1, 2], "list": [1, 2], "each": [1, 2], "experi": 1, "No": [1, 2], "more": 1, "than": 1, "100": 1, "token": 1, "sentenc": 1, "singl": [1, 2], "subfig": [1, 2], "img": [1, 2], "readm": 1, "md": 1, "benchmark_path": 2, "constructor": 2, "object": 2, "generate_embed": 2, "image_path": 2, "captions_list": 2, "model_nam": 2, "mcse_path": 2, "none": 2, "gener": [2, 3], "embed": 2, "specifi": 2, "given": 2, "pair": 2, "paramet": 2, "path": 2, "correspond": 2, "string": 2, "name": 2, "choos": 2, "bert": 2, "scibert": 2, "mcse": 2, "If": 2, "select": 2, "suppli": 2, "folder": 2, "contain": 2, "weight": 2, "return": 2, "type": 2, "n": 2, "d": 2, "numpi": 2, "arrai": 2, "note": 2, "flickr": 2, "roberta": 2, "base": 2, "robert": 2, "ud": 2, "lsv": 2, "generate_embeddings_ds_split": 2, "split_nam": 2, "max_num_sampl": 2, "larger": 2, "param": 2, "data": 2, "split": 2, "default": 2, "maximum": 2, "pick": 2, "natur": 2, "ds_split_embed": 2, "image_nam": 2, "generate_embeddings_hf_anno": 2, "hf_score_typ": 2, "400": 2, "annot": 2, "score": 2, "between": 2, "help": 2, "ocr": 2, "visual": 2, "takeawai": 2, "hf_ds_embed": 2, "empti": 2, "remov": 2, "generate_jsonl": 2, "jsonl": 2, "respect": 2, "get_image_caption_pair": 2, "data_split": 2, "larg": 2, "where": 2, "locat": 2, "withou": 2, "suffix": 2, "get_image_caption_pair_hf": 2, "includ": 2, "hf": 2, "factor": 2, "without": 2, "infer_hf": 2, "scoring_model": 2, "quantization_level": 2, "2": 2, "unseen": 2, "which": 2, "need": 2, "scikit": 2, "mlp": 2, "regressor": 2, "ha": 2, "been": 2, "calcul": 2, "differ": 2, "percentil": 2, "quantiz": 2, "level": 2, "bin": 2, "higher": 2, "inferred_scor": 2, "quantized_scor": 2, "infer_hf_training_set": 2, "mapped_hf_label": 2, "bad": 2, "good": 2, "label": 2, "inferred_hf_df": 2, "row": 2, "file_nam": 2, "text": 2, "inferred_hf": 2, "quantized_hf": 2, "mapped_hf": 2, "map": 2, "panda": 2, "datafram": 2, "train_scoring_model": 2, "hf_embed": 2, "target": 2, "paper": 3, "robust": 3, "facilit": 3, "studi": 3, "applic": 3, "reinforc": 3, "domain": 3, "accompani": 3, "found": 3, "retriev": 3, "exampl": 3, "usag": 3, "api": 3}, "objects": {"": [[2, 0, 0, "-", "FigCapsHF"]], "FigCapsHF": [[2, 1, 1, "", "FigCapsHF"]], "FigCapsHF.FigCapsHF": [[2, 2, 1, "", "generate_embeddings"], [2, 2, 1, "", "generate_embeddings_ds_split"], [2, 2, 1, "", "generate_embeddings_hf_anno"], [2, 2, 1, "", "generate_jsonl"], [2, 2, 1, "", "get_image_caption_pair"], [2, 2, 1, "", "get_image_caption_pair_hf"], [2, 2, 1, "", "infer_hf"], [2, 2, 1, "", "infer_hf_training_set"], [2, 2, 1, "", "train_scoring_model"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"]}, "titleterms": {"exampl": 0, "usag": 0, "retriev": 1, "dataset": [1, 3], "api": 2, "document": [2, 3], "welcom": 3, "figur": 3, "caption": 3, "human": 3, "feedback": 3, "benchmark": 3, "content": 3}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"Example Usage": [[0, "example-usage"]], "Retrieving the dataset": [[1, "retrieving-the-dataset"]], "API Documentation": [[2, "module-FigCapsHF"]], "Welcome to the documentation for Figure-Captioning with Human Feedback benchmark dataset!": [[3, "welcome-to-the-documentation-for-figure-captioning-with-human-feedback-benchmark-dataset"]], "Contents": [[3, "contents"]]}, "indexentries": {"figcapshf": [[2, "module-FigCapsHF"]], "figcapshf (class in figcapshf)": [[2, "FigCapsHF.FigCapsHF"]], "generate_embeddings() (figcapshf.figcapshf method)": [[2, "FigCapsHF.FigCapsHF.generate_embeddings"]], "generate_embeddings_ds_split() (figcapshf.figcapshf method)": [[2, "FigCapsHF.FigCapsHF.generate_embeddings_ds_split"]], "generate_embeddings_hf_anno() (figcapshf.figcapshf method)": [[2, "FigCapsHF.FigCapsHF.generate_embeddings_hf_anno"]], "generate_jsonl() (figcapshf.figcapshf method)": [[2, "FigCapsHF.FigCapsHF.generate_jsonl"]], "get_image_caption_pair() (figcapshf.figcapshf method)": [[2, "FigCapsHF.FigCapsHF.get_image_caption_pair"]], "get_image_caption_pair_hf() (figcapshf.figcapshf method)": [[2, "FigCapsHF.FigCapsHF.get_image_caption_pair_hf"]], "infer_hf() (figcapshf.figcapshf method)": [[2, "FigCapsHF.FigCapsHF.infer_hf"]], "infer_hf_training_set() (figcapshf.figcapshf method)": [[2, "FigCapsHF.FigCapsHF.infer_hf_training_set"]], "module": [[2, "module-FigCapsHF"]], "train_scoring_model() (figcapshf.figcapshf method)": [[2, "FigCapsHF.FigCapsHF.train_scoring_model"]]}})